\chapter{Tensor Algebra}
\section{Introduction}\footnote{Notes taken from Introducing Einstein's relativity by Ray D'Inverno}
To work effectively in Newtonian theory, one reallyneeds the lenguage of vectors. This lenguage, first of all, is mire succint, since it  summarized a set of three equations in one. Moreoveer, the formalism of vectors helps to solver cartain problems more readly, adn, most important of all, the language reveals structure and thereby offers insight. In exactly the same way, in relativity theory, one needs the language of tensors. Again, the language helps to summarize sets of equations succintly and to solve problems more readly, and i reveals structure in the equaions. This part is devoted to learning the formalism of tensors shich is a pre-condition for the rest.

The approach we adopt is to concentrate on the technique of tensors without taking into account the deeper geometrical significance behind the theory. We shall be concerned more with whay you do with tensors rather than what tensors actually are. There are two distinct approaches to the teaching of tensors: the abstract or index-free (coordinate-free) approach and the conventional approach based on indices. There has been a move in recent years in some quarters to introduce tensors from the stars using the more mdodern abstract approach (although some have subsequantly changed their mind and reverted to the conventional approach). The main advantage of this approach is that it offers deeper geometrical insight. However, it has two disadvantages. First of all, it requieres much more of a mathematical background, which in turn takes time to develop. The other disadvantage is that, for all its elegance, when one wants to do real calculation with tensors, as one frequently needs to, then recourse has to be made to indices. We shall adopt the more conventional index approach, because ir will prove faster and more practical. However, we advise those who wish to take their study of the subject further to look at the index-free approach at the first oppoertunity.

\section{Manifolds and coordinates}
*** Quizás se podría complementar algo más ***

We shall start by working with tensors defined in $n$ dimensions since, and it is part of the power of the formalism, there is little extra effort involved. A tensor is an objet defined on a geometric entry called a (differential) \textbf{manifold}. We shall no define a manifold precisely because it would involve us too much of a digression. But, in simple terms, a manifold us simething which 'locally' looks like a bit of $n$-dimensional Euclidean space $\mathbb{R}^{n}$

We shall simply take an $n$-dimensional manifold $M$ to be a set of points such that each point posseses a set of $n$ \textbf{coordinates} $x^{1},x^{2},...,x^{n}$, where each coordinate ranges over a subset of the reals, which may, in particular, range from $-\infty$ to $+\infty$. To start off with, we can think of these coordinates as corresponding to distances or angles in Euclidean space.

\section{Curves and surfaces}
We shall frequently define this curves and surfaces parametrically
\begin{equation}\label{5.1}
  x^{a} = x^{a}(u), \qquad a=1,...,n 
\end{equation}

\begin{equation}       \label{5.3}
  f(x^1,x^2,..., x^n)=0
\end{equation}
Points in an $m$-dimensional subsapce ($m<n$) must satisfy $n-m$ constraints
\begin{align}
\nonumber  f^1(x^1,...,x^n)=&0\\
\label{5.4}          &\vdots    \\
  \nonumber f^{n-m}(x^1,...,x^n)&=0
\end{align}

\section{Transformation of coordinates}
We need to find out how quantities behave when we go from one coordinate system to another one. We therefore consider the change of coordinates $x^{a}\to x'^{a}$ given by the $n$ equations
\begin{equation}\label{5.5}
  x'^{a}=f^{a}(x^1,...,x^n),\qquad a=1,...,n 
\end{equation}
we can write (\ref{5.5}) more succintly as $x'^{a}=f^{a}(x)$ , or more simply
\begin{equation}        \label{5.6}
  \boxed{x'^{a}=x^{a}(x)}
\end{equation}
We next contemplate differentiating (\ref{5.6}) with respect to each coordinates $x^b$
\begin{equation*}
  \left[\pdv{x'^{a}}{x^b}\right] 
\end{equation*}
the determinant $J'$ of this matrix is called the \textbf{Jacobian} of the transformation 
\begin{equation}                   \label{5.8}
  J'=\left|\pdv{x'^{a}}{x^b}\right|
\end{equation}
Assume that thus is non-zero. Then we can solve (\ref{5.6}) for the old coordinates $x^{a}$ and obtain the \textbf{inverse} transformation
\begin{align*}
  x^{a}&=x^{a}(x)\\
  J&=\left|\pdv{x^{a}}{x'^b}\right| \qquad (\mbox{Jacobian of the inverse transformation})\\
  J&=\frac{1}{J'}
\end{align*}
In 3 dimensions, the equation of a surface is given by $z=f(x,y)$, then its total differential is defined to be
\begin{equation*}
  \dd z =\pdv{f}{x}\dd x + \pdv{f}{y}\dd y
\end{equation*}
Then, in an analogus manner, starting from (\ref{5.6}) we define the total differential 
\begin{equation*}
  \dd x'^{a}=\pdv{x'^{a}}{x^1}\dd x^1+\cdots +\pdv{x'^{a}}{x^n}\dd x^n
\end{equation*}
\begin{equation}                                   \label{5.10}
  \dd x'^{a} =\sum_{b=1}^n\pdv{x'^{a}}{x^b}\dd x^b 
\end{equation}
introducing the \textbf{Einstein summation convention}
\begin{equation}                   \label{5.11}
  \boxed{\dd x'^{a}=\pdv{x'^{a}}{x^b}}
\end{equation}
It defines the Kronecker delta as
\begin{equation}
  \delta_b^{a}=\left\{ \begin{array}{lc}
    1 ,& a=b\\
  0 ,& a\neq b\end{array}\right.
\end{equation}
It therefore follow directly from the definition of partial differentiaton that
\begin{equation}                                \label{5.13}
  \pdv{x'^{a}}{x'^b}=\pdv{x^{a}}{x^b}=\delta_b^{a}
\end{equation}

\section{Contravariant tensors}
We shall start with a prototype and then give general definition.

Consider two neighboring points in the manifold $P$ and $Q$ with coordinates $x^{a}$ and $x^{a}+\dd x^{a}$  respectively. The two points define an \textbf{infinitesimal displacement} or \textbf{infinitesimal vector} $\overrightarrow{PQ}$. The components of this vector in the $x^{a}$-coordinate system are $\dd x^{a}$. The components in another coordinate system, say the $x'^{a}$-coordinate system, are $\dd x'^{a}$ which are conected to $\dd x^{a}$ by (\ref{5.11})
\begin{equation}\label{4.14}
  \dd x'^{a}=\pdv{x'^{a}}{x^b}\dd x^b
\end{equation}
The transformation matrix appearing in this equation is to be regarded as being evaluated at the point $P$, i.e, strictly speaking we should write 
\begin{equation}\label{5.15}
  \dd x'^{a}=\left[\pdv{x'^{a}}{x^b}\right]_P\dd x^b 
\end{equation}
A \textbf{contravariant vector} or \textbf{contravariant tensor of rank (order) 1} is a set of quantities, written $X^{a}$ in the $x^{a}$-coordinates system, associated with a point $P$, which trasform under a change of coordinates according to
\begin{equation}\label{5.16}
  \boxed{X'^{a}=\pdv{x'^{a}}{x^b}X^b }
\end{equation}
where the transform matrix is evaluated at $P$. The infinitesimal vector $\dd x^{a}$ is a special case of (\ref{5.16}) where the components $X^{a}$ are infinitesimal. 

A \textbf{contravariant tensor of rank 2} es a set of $n^2$ quantities associated with a point $P$, denoted by $X^{ab}$ in the $x^{a}$-coordinate system, which transform according to 
\begin{equation}\label{5.17}
  X'^{ab}=\pdv{x'^{a}}{x^c}\pdv{x'^b}{x^d}X^{cd }
\end{equation}
An important case is a tensor of zero rank, called a \textbf{scalar} or \textbf{scalar invariant} $\phi$, which transform according to 
\begin{equation}\label{5.18}
  \boxed{\phi' =\phi}
\end{equation}
at $P$.

\section{Covariant and mixed tensors}
Let
\begin{equation}\label{5.19}
  \phi=\phi(x^{a})
\end{equation}
be a real-valued function on the manifold (at every point $P$ in the manifold, $\phi(P)$ produces a real number). Also assume that $\phi$ is continuous and differentiable.

Remembering from (\ref{5.9}), $x^{a}$ can be thought of as a function of $x'^b$, (\ref{5.19}) can be written equivalently as $$\phi=\phi(x^{a}(x'))$$ Remembering Differentiating this with respect to $x'^b$, we obtain 
\begin{equation*}
  \pdv{\phi}{x'^b}=\pdv{\phi}{x^{a}}\pdv{x^{a}}{x'^b }
\end{equation*}
Then changing the order of the terms, the dummy index, and the free index (from $b$ to $a$) gives
\begin{equation}\label{5.20}
  \pdv{\phi}{x'^{a}}=\pdv{x^b}{x'^{a}}\pdv{\phi}{x^b }
\end{equation}
This is the prototype equation we are looking for. Notice that it involves the inverse transformation matrix $\pdv*{x^b}{x'^{a}}$. Thus, a \textbf{convariant vector} or \textbf{covariant tensor of rank (order) 1} is a set of quantities, which transform according to 
\begin{equation}\label{5.21}
  \boxed{X'_a=\pdv{x^b}{x'^{a}}X_b}
\end{equation}
Again, the transform matrix occuring is assumed to be evaluated at $P$.

Similary, we define a covariant tensor of rank 2 by the transform law
\begin{equation}\label{5.22}
  X'_{ab} = \pdv{x^c}{x'^a}\pdv{x^d}{x'^b}
\end{equation}
and so on for higher-rank tensors.

Note the convention that contravariant tensors have raised indices whereas covariant tensors have lowed indices. The way to remember this is the \textbf{co} goes \textbf{below}. The fact that the differentials $\dd x^{a}$ transform as a contravariant vector explains the convention that the coordinate  themeselves are written as $x^{a}$ rather than $x_a$, although note that it is only the differentials and not the coordinates which have tensorial character. 

We can go on on to define \textbf{mixed} tensors in the obvious way. For example, a mixed tensor of rank 3- one contravariant rank and two covariant rank- satisfies
\begin{equation}\label{5.23}
  X'^{a}_{bc}=\pdv{x'^{a}}{x^d}\pdv{x^{e}}{x'^{b}}\pdv{x^f}{x'^{c}}X^{d}_{ef}
\end{equation}
If  a mixed tensor has contravariant rank $p$ and covariant rank $1$, then it is said to have \textbf{type} or \textbf{valence} $(p,q)$. 

Suppose we find in one coordinate system that two tensors, $X_{ab}$ and $Y_{ab}$ say, are equal 
\begin{equation}\label{5.24}
  X_{ab}=Y_{ab}
\end{equation}
Les us multiply both sides by the matrices $\pdv*{x^{a}}{x'^c}$ and $\pdv*{x^b}{x'^c}$ and take the implies summations to get
\begin{equation*}
  \pdv{x^{a}}{x'^c}\pdv{x^b}{x'^d}X_{ab}=\pdv{x^{a}}{x'^c}\pdv{x^b}{x'^d}Y_{ab}
\end{equation*}
Since $X_{ab}$ and $Y_{ab}$ are both covariant tensors of rank 2 it follows that $X'_{ab}=Y'_{ab}$. In other words, (\ref{5.24}) holds in \textbf{any} other coordinate system. In short, a tensor equations whics holds in one coordinate system necessarily holds in \textbf{all} coordinate systems. Thus, although we introduce coordinate systems for convenience un tackling particular problems, if we work with tensorial equations then they hold in all coordinate systems. Put another way, tensorial equations are coordinate-independet. This is something that the index-free or coordinate-free approach makes clear from the outset.

\section{Tensor Fields}
In a vector analysis, a fixed is a vector associated with a point, whereas a vector \textbf{field} defined over a region is an association of a vector to every point in that region. In exactly the same way, a tensor is a set of quantities defined at one point in the manifold. A \textbf{tensor field} defined over some region of the manifold is an assocaition of a tensor of the same valence to every point of the region, i.e: $$P\to T_{b...}^{a...}(P)$$ where $T_{b...}^{a...}(P)$ is the value of the tensor at $P$. The tensor fields is called continous or differentiable if its components in all cordinate systems are continuous  or differentiable functions of the cooridinates. The tensor field is called smooth if its components are differentiable to all orders, which is denoted mathematically by saying that all the components are $C^\infty$. Thus, for example, a contravariant vector fields defined over a region is a set of $n$ \textbf{functions} defined over that region, and the vector field is \textbf{smooth} if the functions are all $C^\infty$. The transformation law for contravariant vector field then becomes
\begin{equation}\label{5.25}
  X'^{a}(x')=\left[\pdv{x'^{a}}{x^b}\right]_PX^b(x)
\end{equation}
at each point $P$ in the region, since the old components $X^{a}$ are functions of the old $x^{a}$-coordinates and the new components $X'^{a}$ are funxtions of the new $x'^{a}$-coordinates.

As in the case of vectors and vector fields in vector analysis, the distinction between a tensor and a tensor field is not always made completely clear. We shall for the most part be dealing with tensor field from now on, but to confo, whith general usage we shall often refer to tensor fields simply as tensors. We will again shorten the transformation law such as (\ref{5.25}) to the form (\ref{5.21}) with everything else being implied. If we wish to emphasize that a tensor is a field. we shall write it in functional form, namely, as $T_{b...}^{a...}(x)$.

